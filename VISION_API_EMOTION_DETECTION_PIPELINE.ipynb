{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "# Imports the Google Cloud client library\n",
    "class ImageAnnotator():\n",
    "\n",
    "    def __init__(self, path_cred=''):\n",
    "\n",
    "        # Set credentials\n",
    "        self.path_cred = path_cred\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path_cred\n",
    "        # Instantiates a client\n",
    "        self.client = vision.ImageAnnotatorClient()\n",
    "    \n",
    "    def get_faces(self, path_img, print_data):\n",
    "\n",
    "        \"\"\" \n",
    "        Annonates image at location path_img returns objects in detected in the image\n",
    "        args:\n",
    "            path_img = string\n",
    "            print_data = bool - prints object data if true\n",
    "        \"\"\" \n",
    "\n",
    "        # The name of the image file to annotate\n",
    "    #         file_name = os.path.join(\n",
    "    #             os.path.dirname(__file__),\n",
    "    #             path_img)\n",
    "        file_name =  path_img\n",
    "\n",
    "        # Loads the image into memory\n",
    "        with io.open(file_name, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "            image = types.Image(content=content)\n",
    "\n",
    "            response = self.client.face_detection(image=image)\n",
    "\n",
    "            faces = response.face_annotations\n",
    "            print( 'Number of faces: ', len(faces))\n",
    "        if print_data:\n",
    "            print('Number of faces found: {}'.format(len(faces)))\n",
    "        return faces\n",
    "\n",
    "    def annotate_image(self, path_img, path_img_an, img_faces):\n",
    "        # read image\n",
    "        emo = ['Angry', 'Surprised','Sad', 'Happy', \"Under Exposed\", \"Blurred\", \"Headwear\"]\n",
    "        likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                            'LIKELY', 'VERY_LIKELY')\n",
    "        string = 'No sentiment'\n",
    "        img = cv2.imread(path_img)\n",
    "        if len(img_faces)>0:\n",
    "            for face in img_faces:\n",
    "                # get vertices\n",
    "    #                 vertices = []\n",
    "                x = face.bounding_poly.vertices[0].x\n",
    "                y = face.bounding_poly.vertices[0].y\n",
    "                x2 = face.bounding_poly.vertices[2].x\n",
    "                y2 = face.bounding_poly.vertices[2].y\n",
    "                img_an = cv2.rectangle(img, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                sentiment = [likelihood_name[face.anger_likelihood],\n",
    "                            likelihood_name[face.surprise_likelihood],\n",
    "                            likelihood_name[face.sorrow_likelihood],\n",
    "                            likelihood_name[face.joy_likelihood],\n",
    "                            likelihood_name[face.under_exposed_likelihood],\n",
    "                            likelihood_name[face.blurred_likelihood],\n",
    "                            likelihood_name[face.headwear_likelihood]]\n",
    "\n",
    "                for item, item2 in zip(emo, sentiment):\n",
    "                    print (item, \": \", item2)\n",
    "\n",
    "                if not (all( item == 'VERY_UNLIKELY' for item in sentiment) ):\n",
    "\n",
    "                    if any( item == 'VERY_LIKELY' for item in sentiment):\n",
    "                        state = sentiment.index('VERY_LIKELY')\n",
    "                        # the order of enum type Likelihood is:\n",
    "                        #'LIKELY', 'POSSIBLE', 'UNKNOWN', 'UNLIKELY', 'VERY_LIKELY', 'VERY_UNLIKELY'\n",
    "                        # it makes sense to do argmin if VERY_LIKELY is not present, one would espect that VERY_LIKELY\n",
    "                        # would be the first in the order, but that's not the case, so this special case must be added\n",
    "                    else:\n",
    "                        state = np.argmin(sentiment)\n",
    "\n",
    "                    string = emo[state]\n",
    "\n",
    "                cv2.putText(img_an,string, (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "\n",
    "    # save image\n",
    "            cv2.imwrite(path_img_an, img_an)\n",
    "\n",
    "        else:\n",
    "            cv2.imwrite(path_img_an, img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy\n",
    "\n",
    "class VideoTransformer():\n",
    "\n",
    "    def __init__(self, fps=30):\n",
    "        self.fps = fps\n",
    "\n",
    "    def video_to_frame(self, path_video, dir_frames):\n",
    "\n",
    "        vidcap = cv2.VideoCapture(path_video)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            cv2.imwrite(dir_frames + \"/frame_\" + str(count).zfill(10) + \".jpg\", image)     # save frame as JPEG file      \n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    def frame_to_video(self, dir_frames, path_video, fps):\n",
    "        num_img = []\n",
    "        images = []\n",
    "        for img in os.listdir(dir_frames):\n",
    "            if img.endswith(\".png\") or img.endswith(\".jpg\"):\n",
    "                # using List comprehension + isdigit() +split() \n",
    "                # getting numbers from string  \n",
    "                data = img.split(\"_\")\n",
    "                data = data[1].split(\".\")\n",
    "                num = data[0]\n",
    "                #print(num)\n",
    "                num_img.append(num)\n",
    "                images.append(img)\n",
    "\n",
    "        sorted_numbers = numpy.argsort(num_img)\n",
    "        images_sorted = []\n",
    "        #print(images)\n",
    "        for i in range(len(images)):\n",
    "            images_sorted.append(images[sorted_numbers[i]])\n",
    "\n",
    "        frame = cv2.imread(os.path.join(dir_frames, images_sorted[0]))\n",
    "        height, width, layers = frame.shape\n",
    "        fourrc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        video = cv2.VideoWriter(path_video, fourrc, fps, (width, height))\n",
    "\n",
    "        for image in images_sorted:\n",
    "            frame = cv2.imread(os.path.join(dir_frames, image))\n",
    "            video.write(frame)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Set parameters\n",
    "PATH_CRED = \"D://OD//live//VideoDetection-503abf24e493.json\"\n",
    "PATH_VID = \"D://OD//live//sample.mp4\"# location video \n",
    "DIR_FRAMES = \"D://OD//live//frames//\"# directory to store frames (will be created)\n",
    "PATH_VID_AN = \"D://OD//live//sample_720p_output.mp4\"# name of annotated video\n",
    "DIR_FRAMES_AN = \"D://OD//live//labeled_frames//\"# directory to store annotated frames (will be created)\n",
    "VID_FPS = 30\n",
    "\n",
    "print(\"running\")\n",
    "\n",
    "# Create objects\n",
    "img_annotator = ImageAnnotator(PATH_CRED)\n",
    "video_transf = VideoTransformer(VID_FPS)\n",
    "\n",
    "# create folder for frames\n",
    "try:\n",
    "    os.mkdir(DIR_FRAMES)\n",
    "except:\n",
    "    print(\"Folder \" + DIR_FRAMES + \" already exists\")\n",
    "    for filename in os.listdir(DIR_FRAMES):\n",
    "        file_path = os.path.join(DIR_FRAMES, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "try:\n",
    "    os.mkdir(DIR_FRAMES_AN)\n",
    "except:\n",
    "    print(\"Folder \" + DIR_FRAMES_AN + \" already exists\")\n",
    "    for filename in os.listdir(DIR_FRAMES_AN):\n",
    "        file_path = os.path.join(DIR_FRAMES_AN, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "# Turn video into frames\n",
    "print(\"Turn video into frames\")\n",
    "video_transf.video_to_frame(PATH_VID, DIR_FRAMES)\n",
    "\n",
    "# iterate through frames\n",
    "print(\"Get informations from images\")\n",
    "for file in os.listdir(DIR_FRAMES):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "        # Get information from images\n",
    "        img_objects = img_annotator.get_faces(DIR_FRAMES+file, True)\n",
    "\n",
    "        # Annotate images\n",
    "        img_annotator.annotate_image(DIR_FRAMES+file, DIR_FRAMES_AN+file, img_objects)\n",
    "\n",
    "# transform frames to video\n",
    "print(\"Transform frames to video\")\n",
    "video_transf.frame_to_video(DIR_FRAMES_AN, PATH_VID_AN,VID_FPS)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
